%%% Author: Steffen Walter  %%%
%%% Alias: firefly-serenity %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% DHBW Stuttgart compliant LaTeX tempalte
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[
book,
a4paper,   
titlepage,  
halfparskip,
12pt        
]{scrartcl}  

%%% packages selection for different purposes (see documentation of the package maintainer for more info)
\usepackage[ngerman]{babel,varioref}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\setkomafont{sectioning}{\bfseries}
\usepackage{ae,aecompl}
%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}
\usepackage{amsmath,amssymb,amstext}
\usepackage{psfrag}
\usepackage{listings}
\lstset{	
	language=bash,
	numbers=left,
	tabsize=2,
	stepnumber=1,
	breaklines=true,
	breakatwhitespace=false,
	backgroundcolor=\color{lightgray},		
} 
\newcommand\inline{\lstinline[basicstyle=\ttfamily]}
%\usepackage{units}
\usepackage[nottoc]{tocbibind}
\usepackage{cite}
\usepackage{caption}
\usepackage{tabto}
\usepackage{xcolor}
\usepackage{longtable}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{tablefootnote}
\usepackage{acronym}
\usepackage{varioref}
\usepackage[hyphens]{url}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% layout
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

% Enables blockset
\sloppy

\usepackage{geometry}
\geometry{a4paper, top=25mm, left=30mm, right=25mm, bottom=30mm, headsep=10mm, footskip=12mm}

%%% PDF options

\usepackage{ifpdf}

\ifpdf %if -> pdflatex
  \usepackage[pdftex]{graphicx}

  \pdfcompresslevel=9
  \usepackage[%
    pdftex=true,      
    backref,    
    pagebackref=false,
    colorlinks=false,
    hyperfootnotes=false,
    bookmarks=true,   
    bookmarksopen=false,
    bookmarksnumbered=false, 
    pdfpagemode=None,
    hidelinks
  ]{hyperref}
  \DeclareGraphicsExtensions{.pdf}
\else %else -> latex 
  \usepackage[dvips]{graphicx}
  \DeclareGraphicsExtensions{.eps}
  \usepackage[dvips, colorlinks=false]{hyperref}
\fi

%%% PDF-Meta-Information 
\hypersetup{
  pdftitle={T1000},
  pdfauthor={Steffen Walter},
  pdfsubject={Secrets Management in großen Firmenumgebungen},
  pdfcreator={Accomplished with LaTeX2e and pdfLaTeX with hyperref-package.},
  pdfproducer={science + computing ag},
  pdfkeywords={},
  breaklinks=true
}
\urlstyle{same}

% provides \AtBeginEnvironment, \patchcmd and \csdef:
\usepackage{etoolbox}

\makeatletter
\newcommand{\acroforeign}[1]{}

% patch the environment to print the foreign definition:
\AtBeginEnvironment{acronym}{%
	\def\acroforeign#1{ (#1)}%
}

% patch the acronym definition to safe the foreign definition:
\patchcmd\AC@@acro
{\begingroup}
{\begingroup\def\acroforeign##1{\csdef{ac@#1@foreign}{##1, }}}
{}
{}

% renew the first output to include the foreign definition if given:
\renewcommand*{\@acf}[1]{%
	\ifAC@footnote
	\acsfont{\csname ac@#1@foreign\endcsname\AC@acs{#1}}%
	\footnote{\AC@placelabel{#1}\hskip\z@\AC@acl{#1}{}}%
	\else
	\acffont{%
		\AC@placelabel{#1}\hskip\z@\AC@acl{#1}%
		\nolinebreak[3] %
		\acfsfont{(\acsfont{\csname ac@#1@foreign\endcsname\AC@acs{#1}})}%
	}%
	\fi
	\ifAC@starred\else\AC@logged{#1}\fi
}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% begin document
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

%%% header and footer before the actual body

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% titlepage
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
\begin{longtable}{lcr}
{\includegraphics[height=1.7cm]{logo}} &
{\includegraphics[height=1.05cm]{blank}} &
{\includegraphics[height=1.7cm]{dhbw}}
\end{longtable}
% \enlargethispage{20mm}
\bigskip
\bigskip
\begin{center}
\vspace*{12mm} {\LARGE\bf Secrets Management in großen Firmenumgebungen}\\
\vspace*{12mm} {\large\bf Bericht Praxis I}\\
\vspace*{3mm} {\large\bf T1000}\\
\vspace*{12mm} des Studiengangs Informationstechnik (B.Sc.)\\ an der Dualen Hochschule Baden-Württemberg Stuttgart\\
% \vspace*{3mm} an der Dualen Hochschule Baden-Württemberg\\
\vspace*{12mm} von\\
\vspace*{3mm} {\large\bf Steffen Walter}\\
\vspace*{12mm} 03.09.2018\\
\end{center}
\vfill
\begin{spacing}{1.5}
\begin{tabbing}
mmmmmmmmmmmmmmmmmmmmmmmmmm \= \kill
\textbf{Bearbeitungszeitraum} \> 9 Wochen\\
\textbf{Matrikelnummer, Kurs} \> 1145690, TINF17IN\\
\textbf{Ausbildungsunternehmen} \> science + computing ag, Tübingen\\
\textbf{Betreuer des Ausbildungsunternehmens} \>Dr. Marcus Camen\\
% \textbf{Gutachter der Hochschule} \> Bernd Beutlin\\
\end{tabbing}
\end{spacing}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% Erklärung
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}

\begin{table}[h]
\centering
  \begin{tabular}{| l |}
  \hline
  \\
  \textbf{Erklärung} \\
  \\
  Ich versichere hiermit, dass ich meine Studienarbeit mit dem Thema: \\
  ``Secrets Management in großen Firmenumgebungen`` selbstständig verfasst \\
  und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe. \\
  \\
  Ich versichere zudem, dass die eingereichte elektronische Fassung mit der gedruckten \\
  Fassung übereinstimmt. \\ \\
  ............................................................\hspace{0.5cm} ......................................\\
  \textit{Ort} \hspace{1cm} \textit{Datum} \hspace{4.2cm} \textit{Unterschrift}\\
  \\
  \hline
  \end{tabular}
\end{table}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}

\large{\textbf{Zusammenfassung}}\\
\\
Das Thema Secrets Management wird zunehmend zu einem zentralen Thema in der
elektronischen Datenverarbeitung.  Unter dem Begriff ist im Folgenden vor
allem der Umgang mit geheimen Informationen gemeint.  Geheim sind
Informationen dann, wenn es schädlich ist wenn diese Informationen
Unbefugten zugänglich sind. Beispiele für derartige Informationen sind
Passwörter, geheime Schlüssel oder geheime Dokumente.  In der
Praxisarbeit soll evaluiert werden welche Anforderungen große Unternehmen
an ihr Secrets Management stellen und welche Programme dabei häufig zum
Einsatz kommen.  In einem weiteren Schritt soll festgestellt werden welche
Anforderungen durch jene Programme nicht erfüllt werden.  Im Anschluss
soll eine voll umfängliche Secrets Management Software daraufhin untersucht
werden, in wie fern Unzulänglichkeiten von gängiger Software behoben
werden können.  Es soll auch beleuchtet werden, welche zusätzlichen
Anforderungen Cloud Umgebungen mit sich bringen.  Hierbei zu beachten ist,
welche Vorteile durch alternative Software zu erzielen sind.  Für die
Evaluierung soll eine virtuelle Umgebung erstellt werden, in welcher die
Funktionen getestet werden.
\newpage
\thispagestyle{empty}

\large{\textbf{Abstract}}\\
\\
The topic of secrets management is becoming an uprising matter in digital data processing.
In this report the term of secrets management is mainly used to describe the handling of confidential information.
Information is considered confidential, if it can be used to to harm the owner of the secret in any way.  
Examples for information that meets this criteria would be password, private digital key or simply confidential documents.
In the paper shall be evaluated which requirements enterprises have for their secrets management and which software is currently used to try and fulfill those needs.
Subsequently the gaps between requirements and the functional range of the used Software shall be emphasized.
Furthermore a secrets management software with a modern approach shall be examined to find out whether or not this software is able to fill in the gaps of traditional software.
Also the aspect of cloud environment shall be considered as a factor of importance. 
To achieve this task a virtual environment shall be implemented to test the features of the chosen software.


%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% dictionaries
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{fancy}
\fancyhf{} %% remove all previous settings

\newpage
\tableofcontents
\newpage
\pagestyle{fancy}
\fancyhf{} %% clear all previous settings
\fancyhead[R]{\thepage} %% pagenumber in the upper right corner
\fancyhead[L]{VERZEICHNISSE} %% section description in the upper left corner
\pagenumbering{roman}
\section*{Abkürzungsverzeichnis} %%Title for list of acronyms
\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
\begin{acronym}[RADIUS]
 \acro{ACL}{Zugriffskontrollliste \acroforeign{Access Control List}}
 \acro{AD}{Active Directory}
 \acro{API}{Schnittstelle zur Anwendungsprogrammierung \acroforeign{Application Programming Interface}}
 \acro{AWS}{Amazon Web Dienste \acroforeign{Amazon Web Services}}
 \acro{CA}{Zertifizierungstelle \acroforeign{Certificate Authority}}
 \acro{CAE}{Rechnergestützes Entwicklung\acroforeign{Computer Aided Engineering}}
 \acro{HCL}{Hashicorp Konfigurtaions Sprache \acroforeign{Hashicopr Configuration Language}}
 \acro{IT}{Informationstechnik}
 \acro{JSON}{Java Script Objekt Notation}
 \acro{JWT}{\ac{JSON} Web Token}
 \acro{LDAP}{Leichtgewichtiges Verzeichniszugriffsprotokoll\acroforeign{Lightweight Directory Access Protocol}}
 \acro{MIT}{Massachusetts Institute of Technology}
 \acro{OECD}{Organisation für wirtschaftliche Zusammenarbeit und Entwicklung \acroforeign{Organisation for Economic Co-operation and Development}}
 \acro{OIDC}{OpenID Connect}
 \acro{PKI}{Public Key Infrastruktur}
 \acro{RADIUS}{Authentifizierungsdienst für sich einwählende Benutzer \acroforeign{Remote Authentication Dial-IN User Service}}
 \acro{SSL}{Spezifikation zur Verschlüsselten Datenübertragung\acroforeign{Secure Socket Layer}}
 \acro{TLS}{Transportschicht Sicherheit \acroforeign{Transport Layer Security}}
\end{acronym}
\listoffigures
\setcounter{table}{0}
\listoftables
\lstlistoflistings
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% glossary
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\newpage

\pagestyle{fancy}
\fancyhf{} %% clear all previous settings
\fancyhead[R]{\thepage} %% pagenumber in the upper right corner
\fancyhead[L]{GLOSSAR} %% section description in the upper left corner

\section*{Glossar} 
\addcontentsline{toc}{section}{Glossar}
\begin{acronym}
	\acro{Authentifizierung:}{der Identitätsnachweis einer Person, Maschine oder eines Dienstes, gegenüber einer weiteren Instanz} 
	\acro{Autorisierung:}{die explizite Freigabe um auf einen geheimen Inhalt zuzugreifen}
	\acro{Chef:}{eine Software zur automatisierten Installation von fertig konfigurierten Betriebssystemabbildern.}
	\acro{Computercluter:}{eine Ansammlung von, meist identischer, Harware, welche zu einer logischen Einheit zusammengefasst wird. Der Cluster wird meist verwendet um komplexe Berechungen zu lösen, die auf einzenen Computern sehr lange dauern würde.}
	\acro{Dienst:}{eine autarke Einheit, welche eine spezifizierte Aufgabe bzw. Funktionalitaet erfuellt und diese ueber keine klar definierte Schnittstelle zur Verfuegung stellt}
	\acro{KeePass Passwort Safe:}{ein quelloffener Passwortmanager, dazu designed wurde viele Passörter auf sichere Art und Weise zu speichern. Der Zugang zu diesem Passwortsafe wird allein durch ein einziges Masterpasswort gewährt.}
	\acro{OpenStack:}{der Markenname eines quelloffenen Betriebssystems welches entwickelt wurde um eine Cloud Computing (siehe Kapitel \vref{subsec:cloud}) Infrastruktur bereit zu stellen.\cite[S. 2]{barbican}}
	\acro{Skalierbarkeit:}{die Fähigkeit eines Systems zur flexiblen Änderung ihrer Größe. Der Begriff wird meist dann verwendet wenn es um ein Ausweitung des gefragten Systems geht.}
\end{acronym}

\newpage
\begin{onehalfspacing} %% set space between lines to 1.5
\pagestyle{fancy}
\fancyhf{} %% remove all previous settings
%\renewcommand{\headrulewidth}{0pt} %%% activate to remove seperation line between head and main body
\fancyhead[L]{\rightmark} %% section name and number in the upper left corner
\fancyhead[R]{\thepage} %% pagenumber in upper right corner
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% begin main document
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%

\section{Einleitung}
\label{sec:einleitung}

\subsection{Gegenstand und Ziele des Praxisberichts}
\label{subsec:ziele}

\subsection{Einführung in das Thema}
\label{subsec:einfuehrung}
Mit der fortschreitenden Digitalisierung nahezu aller Wirtschaftszweige steigt auch die Relevanz für die Absicherung der daraus resultierenden \ac{IT}-Infrastrukturen.
Zusätzlich zu den eigenen Sicherheitsbelangen des Betreibers einer informationstechnischen Umgebung kommen auch noch gesetzliche Regelungen wie das IT-Sicherheitsgesetz zum Tragen. 
Vor allem im Bezug auf eine zunehmende Verlagerung des \ac{IT}-Betriebs hin zum Cloud Computing und den damit verbundenen Problemen dezentraler Datenhaltung (vor allem bei den public und hybrid Modellen), entstehen häufig unübersichtliche Sicherheitskonzepte. Durch die große Varianz der Szenarien, vor allem auch in Anbetracht unterschiedlicher Sicherheitsniveaus der Daten sind die verwendeten Konzepte der unterschiedlich.\cite[S. 7f]{risiko}\\
Spionage- und Sabotage-Angriffe werden aus den unterschiedlichsten Motivationen und auch von den Unterschiedlichsten Objekten verübt. So reicht das Spektrum der Angreifer von Kleinkriminellen über Geheimdienste und Terroristen bis hin zur organisierten Kriminalität. Die Aufgabe der \ac{IT}-Sicherheit besteht also darin, die potentiellen Angreifer in ihren Erwägungen zu berücksichtigen und und die Werte und Geheimnisse der Unternehmen zu schützen. Ein zentraler Faktor bei der Entwicklung eines Sicherheitskonzepts auf dieser Grundlage ist es, ein stringentes Konzept zur Kontrolle der Autorisierung einer Person oder eines Dienstes auf unterschiedliche Bereiche in der zu betreuenden Umgebung. Neben der Autorisierung spielt auch die Authentifizierung, denn es muss zu jedem Zeitpunkt sichergestellt werden, dass die Autorisierung auch der richtigen Person oder Anwendung übertragen wurde.\cite[S. 9]{risiko}\\
Der Aufwand welcher für \ac{IT}-Sicherheitskonzept betrieben wird bemisst sich meistens am Schaden, der zu erwarten ist, sollten geheime Daten in die Hände Dritter gelangen. Da es kaum verlässliche Daten zur Quantität der Kosten gibt, die durch einen kritischen Sicherheitsvorfall verursacht werden, ist die daran orientierte Bemessung der Sicherheitsvorkehrungen umstritten. Generell gibt es verschiedene Faktoren die bei der qualitativen Kostenabschätzung berücksichtigt werden müssen, so wird im allgemeinen zwischen direkten und indirekten Kosten unterschieden.\cite[S. 12]{kosten}
\subsubsection{Direkte Kosten}
Die direkten Kosten die durch Wirtschaftsspionage entstehen können bemessen sich zu allererste einmal an dem direkten Wert des gestohlenen Eigentums. Dieser Wert lässt sich ermitteln durch den finanziellen Gegenwert, den das Eigentum hat und an den zu erwartenden Gewinneinbußen durch den Verlust (der Exklusivität) des Eigentums. Weiterhin entstehen direkte Kosten durch die das Desaster-Recovery, das heißt durch die Schritte die eingeleitet werden müssen um den Status Quo wieder herzustellen. Zu guter Letzt werden auch noch diejenigen Kosten hinzugezählt, die durch die Prävention einer Wiederholung des Ereignisses entstehen, dazu zählen Prozessänderungen, Sicherheitsunterweisungen und weitere direkte Maßnahmen.\cite[S. 13]{kosten}
\subsubsection{Indirekte Kosten}
Zu den indirekten Kosten werden vor allem die Umsatzausfälle durch Image- und Markenschäden gezählt. Außerdem entstehen hohe Umsatzeinbußen durch Plagiate welche in folge des Gestohlenen Eigentums verbreitet werden können. Plagiate können deutlich günstiger angeboten werden, da die Kosten für Forschung und Entwicklung nicht in den Preis eingerechnet werden müssen.\cite[S. 14]{kosten}
\subsubsection{Versuch einer Quantifizierung}
Nach Schätzungen der \ac{OECD} belaufen sich die Schäden durch Fälschungen und Produktpiraterie weltweit auf 638 Milliarden US-Dollar pro Jahr. Die Schätzungen diesbezüglich gehen aber weit auseinander. Es scheint jedoch Sicher zu sein, dass Sich die Schäden im dreistelligen Milliardenbereich bewegen. Für die deutsche Wirtschaft liegen die Schätzungen zwischen 20 und 50 Milliarden Euro.\cite[S. 16f]{kosten}
\subsubsection{Anforderung an Sicherheitssoftware}
\label{subsubsec:anforderung}
Spezifische Anforderungen die an eine Software zum Secrets Management gestellt werden, können wie folgt zusammengefasst werden:

\begin{itemize}
  \item Auffindbarkeit - Es muss zu jedem Zeitpunkt klar sein, wo sich Secrets im Unternehmen befinden.
  \item Nachvollziehbarkeit - Es muss möglich sein, Verantwortliche zu nennen.
  \item Break Glass Szenario - Es muss einen Weg geben, im Fall eines Angriffs den Schaden einzugrenzen.
  \item Verfügbarkeit - Daten müssen jederzeit zugänglich sein.
  \item Integrität - Daten müssen immer vollständig und korrekt sein.
  \item Verlässlichkeit - Daten müssen authentisch sein, Kommunikationswege nachvollziehbar.
  \item Autorisierung - Der Zugriff auf Daten soll nur dann möglich sein, wenn die betroffene Person/Maschine berechtigt ist (minimale Berechtigungsvergabe).
  \item Benutzerfreundlichkeit - Einfacher Zugriff von Mensch und Maschine.
  \item Authentifizierung - Sichere Anmeldeverfahren müssen zur Verfügung stehen.
  \item Credential Management Systeme zur sicheren Erstellung, Speicherung und Änderung sollen zur Verfügung stehen.
  \item Das Risiko, dass kompromittierte Verschlüsselung zum Verlust oder dem unberechtigten Offenlegen von Informationen führt, muss kontrollierbar sein.
\end{itemize}

Rechtliche Aspekte werden durch den Vorliegenden Bericht nicht weiter beleuchtet.\footnote{Die Inhalte aus Kapitel \vref{subsubsec:anforderung} wurden in Anlehnung an interne Dokumenten eines großen Unternehmens und Gesprächen mit \ac{IT}-Administratoren erarbeitet}
\newpage
\section{Stand der Technik}
Das folgende Kapitel liefert die theoretischen Grundlagen für die praktische Umsetzung der Projektarbeit. Es wird eine Breite Übersicht über den Themenkomplex des Secrets Management gegeben und es wird gezeigt welche Softwareprodukte aktuell in Unternehmen zum Einsatz kommen um Probleme die mit den Themenkomplexen Authentifizierung und Autorisierung in Verbindung stehen zu lösen. Außerdem wird aufgezeigt welche neuen Herausforderungen das Arbeiten unter Verwendung von Cloud Computing mit sich bringt. 

\subsection{Das Passwort}
\label{subsec:pass}
Das Passwort ist die einfachste und am häufigsten verwendete Methode um eine Authentifizierung zwischen einem Mensch und einem Computersystem durchzuführen. Es ist leicht zu implementieren und leicht zu bedienen. Es gibt allerdings eine Reihe an Angriffsszenarien bei denen das klassische Passwort als authentifizierender Faktor versagt.
\begin{itemize}
	\item Das Passwort kann beim Eintippen durch einen dritten gesehen oder gefilmt werden. 
	\item Passwörter können über sogenannte Brute-force Angriffe ``erraten`` werden. Um diese Angriffe durchzuführen gibt es spezielle Programme, die so lange alle möglichen Kombinationen an Tastaturzeichen ausprobieren, bis sie das Passwort herausgefunden haben. 
	\item Wenn Passwörter über das ein Netzwerk übertragen werden, können sie durch spezielle Software abgegriffen werden. Außerdem gibt es spezielle Software, welche die Tastatureingaben am Computer protkollieren kann. Solche Software kann dazu verwendet werden Passwörter die an betreffenden Endgeräten eingegeben werden an einen Angreifer zu übermitteln.
	Ein weiteres Angriffsszenario stellt das sogenannte Login Spoofing dar. Hierbei wird ein Anmeldefenster gefälscht, welches möglichst gleich aussieht wie das original. Wenn der Nutzer sein Passwort in das gefälschte Fenter eingibt, wird es gespeichert oder direkt an den Angreifer übermittelt. 
\end{itemize}
Jeder dieser Angriffe reicht aus um Systeme zu täuschen die zur Authentifizierung allein auf Passwörter setzen. In den meisten Unternehmen ist es aus diesen Gründen nicht erlaubt das gleiche Passwort für unterschiedliche Dienste zu verwenden. Außerdem gibt es versuche durch Passwortrichtlinien die Komplexität der Passwörter zu steigern, sodass zum Beispiel Brute-force Angriffe länger dauern und sich nicht mehr lohnen. Zusätzlich werden Schwellwerte für fehlgeschlagene Anmeldeversuche festgelegt um zu vermeiden, dass Passörter beliebig oft ausprobiert werden können. Diese Maßnahmen verringern zwar die Zahl der erfolgreichen Angriffe, stehen jedoch im Widerspruch zur einfachen Benutzbarkeit. Ein hoher Aufwand für die \ac{IT}-Abteilungen muss aufgebracht werden um Passwörter zurückzusetzen und die Sicherheitsmechanismen für jeden Dienst zu implementieren.\cite[S. 3ff]{hong}\\
Auf Grund der vielen Angriffsmöglichkeiten gibt es viele Stimmen, die das Ende des Passworts, wie wir es kennen, fordern. Es gibt außerdem viele Empfehlungen ein Passwort am besten zu erzeugen ist um eine Steigerung der Sicherheit gegenüber Angriffen zu erreichen. Was bleibt ist die menschliche Komponente beim Umgang mit Passwörtern. Da Menschen sich auf Bequemlichkeit nicht an die Empfehlungen zur Erstellung eines ``sicheren`` Passworts halten und dies sich auch nur bedingt überprüfen lässt ohne neue Angriffsflächen zu bieten, bleibt das Problem bestehen, dass Passwörter ``geknackt`` werden und Angreifer Zugriff auf sensible Daten bekommen. Es gibt mittlerweile einen Trend zur sogenannten Zwei-Faktor Authentifizierung wobei die zum Identitätsnachweis nicht allein das Passwort verwendet wird, sondern ein weiterer Faktor hinzugenommen wird. Es gibt unterschiedliche Methoden wie solch ein weiterer Faktor aussehen kann, so gibt es zum Beispiel Codes die über die Mobiltelefone der User zugeschickt werden und die nur einmal und für eine kurze Zeitperiode verwendet werden können. Da es bis jetzt aber noch keine vollkommene Alternative zu Passwörtern gibt, ist es sehr wahrscheinlich, dass das Passwort noch einige Zeit also Teil der Authentifizierung bestehen bleiben wird.\cite{pass}

\subsection{Identitäten}
\label{subsec:ident}
Vorwiegend wird der Begriff der Identität in der Soziologie besprochen, er spielt allerdings auch in der Informatik eine wichtige Rolle. Identitäten sind in der Regel definierte Zusammensetzung von Rollen und Eigenschaften eines Objekts. Zu dieser Kombination kommt ein, innerhalb einer Organisationseinheit, eindeutiger Identifikator. Durch ihre Beschreibung kann abgeleitet werden wie die Identität vorzugehen hat und welche Schnittstellen für sie von Relevanz sind. Zudem wird davon ausgegangen, dass eine Identität einer gewissen Persistenz unterliegt, das heißt, dass sich Eigenschaften und Rollen nicht ständig ändern. Genauso wie es möglich ist, dass mehrere Objekte die gleiche Zusammensetzung von Eigenschaften haben, ist es ebenso möglich dass einzelne Objekte mehreren Identitäten zugeordnet werden können. Für Menschen die sich selten im Kontext der \ac{IT} Administration bewegen mag der Gedanke Nahe liegen, dass es sich bei einer Identität um eine natürliche Person handelt. Dieser Schluss ist zwar nicht falsch, greift aber etwas zu kurz, denn nicht ausschließlich natürliche Personen erfüllen die Voraussetzungen die eine Identität ausmachen. Neben natürlichen Personen werden auch \ac{IT}-Systeme und \ac{IT}-Anwendungen durch Identitäten beschrieben. \cite[S. 21ff]{kerberos2}

\subsection{Digitale Zertifikate}
\label{subsec:zert}
Neben der in Kapitel \vref{subsec:pass} beschriebenen Authentifizierungsmethode via Passwort gibt es weitere Möglichkeiten die Integrität einer Identität gegenüber einem informationstechnischen System nachzuweisen. Eine wichtige Rolle spielen hierbei sogenannte digitale Zertifikate. Diese Zertifikate können dazu verwendet werden den öffentlichen Schlüssel eines asymmetrischen Verschlüsselungssystems einer Identität zuzuordnen. Der öffentliche Schlüssel wird zu diesem Zweck mit mehreren Merkmalen verknüpft, die gesammelt dazu geeignet sind den Eigentümer des Schlüssels eindeutig zu authentifizieren. Zur Validierung eines Zertifikats wird eine sogenannte \ac{CA} verwendet; diese übernimmt die Aufgabe der Verknüpfung der zu authentifizierenden Instanz und dem öffentlichen Schlüssel. Grundlage für die eine erfolgreiche Authentifizierung mit digitalen Zertifikaten ist das Vertrauen gegenüber der Zertifizierungsinstanz (\ac{CA}). Jedes Zertifikat enthält eine Seriennummer die von der \ac{CA} nur einmal vergeben wird und damit den Halter des Schlüssels eindeutig identifizieren kann. Die bekannteste Implementierung eines derartigen Zertifizierungssystems ist das X.509 Zertifikat, welches zum Beispiel bei der Absicherung von Netzwerkkommunikation mit \ac{TLS} (häufig als \ac{SSL} bezeichnet) eingesetzt wird. Neben der Seriennummer enthalten digitale Zertifikate in der Regel noch Informationen wie Versionsnummer, Informationen über die Identität, Informationen über die Gültigkeitsdauer, die digitale Signatur der validierenden \ac{CA}, Informationen zum verwendeten Verschlüsselungsalgorithmus und Informationen zum Gültigkeitsbereich sowie des vorgesehenen Anwendungsbereichs des kryptographischen Schlüssels.\cite[S. 144]{kerberos2}\\
Das Zertifikat an sich enthält also ausschließlich öffentliche Informationen und kann somit nicht allein zur Authentisierung verwendet werden. Allein der Besitz des privaten Gegenstücks zum öffentlichen Schlüssel, der im Zertifikat seine Zuordnung erhält, eignet sich schlussendlich zum eindeutigen Identitätsnachweis. Der kritische Punkt ist als der private Schlüssel, welcher unbedingt vor dem Zugriff dritter geschützt werden muss, denn andernfalls kann ein unrechtmäßiger Besitzer das Zertifikat verwenden um sich für den eigentlichen Halter des Zertifikats auszugeben und damit beispielsweise an geheime Informationen gelangen. Typischerweise sind derartige Zertifikate ein bis zwei Jahre gültig\cite[S. 145f]{kerberos2}\\

\subsection{Tokenbasierte Authentifizierung und Autorisierung}
\label{subsec:token}
Ein Token wird verwendet um einen Zugangsschlüssel zu erzeugen welcher sich dazu eignet sich gegenüber einem geschützten System zu authentifizieren. Beim Token handelt es sich Stück Hardware das nicht selten über ein LCD-Display verfügt um dort den generierten Zugangsschlüssel auszugeben. Umgangssprachlich wird auch der erzeugte Zugangsschlüssel in der \ac{IT} oft als Token bezeichnet zur Unterscheidung wir im folgenden von Hardware- bzw. Software-Token gesprochen. 

\cite[S.141ff]{kerberos2}

\subsection{Cloud Computing}
\label{subsec:cloud}
Der Begriff des Cloud Computing beschreibt den bedarfsorientierten Zugriff auf Internetdienste und andere \ac{IT} Ressourcen die durch den Provider Schlüsselfertig zur Verfügung gestellt werden und dynamisch an den Bedarf des Kunden angepasst werden können. Bei der Bereitstellung von Cloud Services wird zwischen folgenden Charakteristika unterschieden\cite[S. 8]{cloudsec}\\
\textbf{Bedarfsgerechter Zugriff:} Der Bedarf des Kunden kann in Echtzeit an die aktuellen Bedürfnisse angepasst werden und findet insbesondere ohne menschliche Interaktion auf Seite des Providers statt. Parameter die unter diese Art von Anpassungen fallen sind Rechenleistung, Speichergröße und Bandbreitenkapazität.\cite[S. 8]{cloudsec}\\
\textbf{Netzwerkanbindung:}  Viele Cloud Provider ermöglichen den Zugriff auf ihre Dienste von sehr unterschiedlichen Endgeräten. Eine Steuerung über Smartphone oder Tablet ist dabei nicht die Seltenheit. Die Netzwerkanbindung ist in der Regel durch eine Breitbandverbindung realisiert und verfügt über definierte Schnittstellen.\cite[S. 8]{cloudsec}\\
\textbf{Ressourcenbündelung:} Durch gesetzliche Vorschriften und eigenen Sicherheitsbeschränkungen sind einige Kunden verpflichtet bestimmte Daten auf Servern in festgelegten geografischen Regionen zu lagern. Dieses Vorgehen widerspricht dem Prinzip der Ressourcenbündelung, das vorsieht, dass die Bereitstellung der gewünschten Ressource immer von dem Rechenzentrum aus geschieht, wo gerade am wenigsten Auslastung zu verzeichnen ist. Einige Cloud Provider bieten daher die Möglichkeit der regionalen Eingrenzung an.\cite[S. 8]{cloudsec}\\
\textbf{Skalierbarkeit:} Wenn die vorangegangen Punkte kombiniert werden, ergibt sich daraus die Möglichkeit flexible und bedarfsgerecht Ressourcen zu erhöhen und wieder freizugeben. In vielen fällen erfolgt dieser Prozess vollautomatisch und nimmt dem Kunden in diesem Bereich jegliche nichtmonetäre Ressourcenplanung ab.
\cite[S. 9]{cloudsec}\\
\textbf{Verbrauchsabhängige Bezahlung:} Die Bezahlung von Cloud Diensten orientiert sich nicht selten an den tatsächlich verbrauchten Ressourcen in Relation zur zeitlichen Belegung. So können relativ einfach Kalkulationen angestellt werden, aus denen sich ergibt ob sich die Nutzung von Cloud Computing für die eigenen Zwecke lohnt.
\cite[S. 9]{cloudsec}\\

\textbf{Dynamische Zertifizierung:} das in Kapitel \vref{subsec:zert} beschriebene Verfahren der Nutzung von digitalen Zertifikaten in seiner klassischen Form stößt beim Betrieb von Cloud Anwendungen an seine Grenzen und wird daher durch neue Konzepte wie zum Beispiel die dynamische Zertifizierung ersetzt. Klassische Methoden zur Zertifizierung liegt die Annahme zu Grunde, dass die Identitäten , wie in Kapitel \vref{subsec:ident} beschrieben, über längere Zeit eine konstante Zusammensetzung von Rollen und Eigenschaften haben. Falls nicht manuell getriggert, wird nach der definierten Gültigkeitsperiode eines Zertifikats geprüft ob das Objekt, weiterhin die Voraussetzungen für des Zertifizierungsprozesses erfüllt, um bei erfolgreicher Prüfung eine Rezertifizierung einzuleiten.\cite{cloudabs}\\
Durch die Schnelllebigkeit von Cloud-Diensten kommt es häufig vor, dass sich die Eigenschaften eines Dienstes im laufenden Cloudbetrieb ändern. Durch den Aufbau von Cloudumgebungen sind diese Änderungen für den Endnutzer allerdings nicht erkennbar und ein Zertifikat, welches nach den klassischen Prozessen erzeugt wurde lässt darauf schließen, dass der Dienst für die Gültigkeitsdauer des Zertifikats weiterhin die Ursprünglichen Eigenschaften aufweist. Dynamische Zertifizierung versucht dieses Problem zu lösen indem eine ständige Kontrolle der Zertifikatsanforderungen von Cloud-Diensten zur Laufzeit durchgeführt wird, um infolgedessen jede Änderung in den Eigenschaften direkt Protokollieren zu können. Um ein kontinuierliches Audit der Dienste zu realisieren zu können, werden verschiedene Ansätze verfolgt. Neben spezieller Test- und Monitoringsoftware welche die eine Anwendung zur Laufzeit überprüfen können auch sogenannte Trusted Platform Module verwendet werden um eine Prüfsumme über ein gewünschte Ziel (zum Beispiel die zu kontrollierende Cloud-Anwendung) zu bilden und diese mit dem historischen Zustand zu vergleichen. Um diese Art von Auditierungvorgänge ich bestehende Zertifizierungsmodelle zu integrieren, werden häufig zusätzlich noch ausgebildete Auditoren beschäftigt, die Änderungen in Dokumenten und bei den beteiligten Stakeholdern feststellen sollen.\cite[S. 114ff]{cloudsec}

\subsection{Vergleichende Aufstellung unterschiedlicher Softwareprodukte}
\label{subsubsec:stand}
Um die in Kapitel \vref{subsec:einfuehrung} beschriebenen Themenkomplexe der Autorisierung und Authentifizierung in Firmenumgebungen umzusetzen gibt es verschiedene Ansätze. Im folgenden sollen einige gängige Softwareprodukte, die die genannten Aufgaben erfüllen sollen vorgestellt und auf ihre Tauglichkeit zur voll umfänglichen Erfüllung der in Kapitel \vref{subsubsec:anforderung} beschriebenen Anforderung untersucht.
\begin{table}[h]
\centering
  \begin{tabular}{|l|c|c|c|}
  \hline
  \textbf{Funktion} & \textbf{Kerberos} & \textbf{Pleasant Pass-} & \textbf{Hashicorp}\\
  Näheres: & & \textbf{word Server} & \textbf{Vault} \\
  Kapitel \vref{subsubsec:anforderung} & & (Multi-User KeePass) &\\
  \hline
  \hline
  Auffindbarkeit & \checkmark & \checkmark & \checkmark\\
  \hline
  Nachvollziebarkeit & $\times$ & \checkmark & \checkmark\\
  \hline  
  Break Glass Szenario & $\times$ & $\times$ & \checkmark\\
  \hline
  Verfügbarkeit & \checkmark & \checkmark & \checkmark\\
  \hline
  Integrität & \checkmark & \checkmark & \checkmark\\
  \hline
  Verlässlichkeit & \checkmark & ? & \checkmark\\
  \hline
  Autorisierung & $\times$ & \checkmark & \checkmark\\
  \hline
  Authentifizierung & \checkmark & \checkmark & \checkmark\\
  \hline
  Credential Management & \checkmark & \checkmark & \checkmark\\
  \hline
  Kontrollierbarkeit & $\times$ & \checkmark & \checkmark\\
  \hline
  \end{tabular}
\caption[Softwarevergleich]{Vergleich verschiedener Softwareprodukte\cite[S. 4f, 13, 57 ]{kerberos}\cite{pleasant}\cite{vault}}
\label{tab:ver}
\end{table}
Die Programme werden in unterschiedlichen Versionen angeboten. Einige der beschriebenen Funktionen stehen möglicherweise in der kostenfreien Version nicht zur Verfügung.

\subsubsection{Kerberos}
Der Name Kerberos kommt ursprünglich aus der griechischen Mythologie, wo er für den dreiköpfigen Hund verwendet wurde, der den Eingang zu Unterwelt bewacht. 
Das Projekt wurde in den achtziger Jahren am \ac{MIT} ins als Teil des sogenannten Athena-Projekts ins Leben gerufen. Die großen Stärken von Kerberos liegen in der Authentifizierung und der verschlüsselten Nachrichtenübermittlung. Schon zu Beginn des Projekts lag, neben den Sicherheitsaspekten, der Fokus ganz klar auf der Skalierbarkeit des Systems. 
Verschlüsselt wird mit symmetrischer Verschlüsselung und einem vorher vereinbarten geheimen Schlüssel. Kerberos unterstützt inzwischen auch den Einsatz von Passwörtern, ist dafür aber ursprünglich nicht entwickelt worden. 
Mit diesen Grundfunktionen kann eine relative sichere und authentisierte Kommunikation zwischen Nutzer und Dienst in einem Umfangreichen Netzwerk gewährleistet werden.\\
Durch die Tatsachen, dass die Software unter einer Open-Source-Lizenz veröffentlicht wurde, können Sicherheitslücken schnell aufgespürt und behoben werden. Außerdem ist es dadurch möglich, dass Unterschildleiche Unternehmen an dem Code mitarbeiten und diesen ständig verbessern und dies geschieht auch zum Beispiel durch Microsoft. Kerberos kommt heutzutage selten als Einzelsystem vor, sondern es wird entweder mit anderen Softwarekomponenten kombiniert, oder es kommt als Bestandteil einer umfangreicheren Software wie zum Beispiel Microsoft \ac{AD} vor.\cite[S. 137f]{kerberos2}\\
Die Authentifizierung mit Kerberos wird über sogenannte Tickets organisiert. Der Client fordert ein Ticket beim Authentifizierungsserver an. Der Authentifizierungsserver verschlüsselt anschließend das Ticket mit dem Schlüssel des Clients und dem Schlüssel des gewünschten Dienstes. Mit diesem Ticket kann der Client sich nun mit dem gewünschten Dienst verbinden und es ist gewährleistet, dass sowohl der Dienst, als auch der Client diejenigen sind für die sie sich ausgeben.  Der Zugrundeliegende Ablauf wird in Abbildung \vref{fig:kerb} nochmal genauer und anschaulicher gezeigt. Bei der gegenseitigen Authentifizierung ist es nicht entscheidend auf welchem Betriebssystem Client und Server basieren, weil dies der Fall ist kann bei Kerberos von einer plattformübergreifenden Software gesprochen werden.
\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{kerberos.png}
	\caption[Kerberos]{Authentifizierung mit Kerberberos \cite[vgl. S.140]{kerberos2}}
	\label{fig:kerb}
\end{figure}
Kritisch im Zusammenhang mit Kerberos ist die Fokussierung auf einen Zentralen Server, dieser muss so dimensioniert sein, dass er alle Anfragen verarbeiten kann und, dass durch einen Hardwaredefekt der Betrieb nicht stoppt. Ein weiterer Nachteil ist die fehlende Verschlüsselung des Netzwerkverkehrs. Außerdem werden Sitzungsschlüssel zwischenzeitlich auf dem Client gespeichert und sind so ein leichtes Ziel für Angreifer die Zugriff auf die Clientmaschine haben. Es kann ebenfalls kritisiert werden, dass die Änderung eines Nutzerpassworts immer mit der Änderung des geheimen Schlüssels einhergeht. Im allgemeinen macht Kerberos aber genau das was es soll und seine Popularität zeigt auch, dass es diese Aufgabe sehr zufriedenstellend löst. Mit diversen Erweiterungen lassen sich die erwähnten Unzulänglichkeiten auch umgehen.\cite[vgl. S.138f]{kerberos2}

\subsubsection{Pleasant Password Server}
Beim Pleasant Password Server Handelt es sich nach eigenen Angaben um eine serverbasierte KeePass Passwort Safe. Im Unterschied zu seinem kleinen Bruder ist der Pleasant Passowrd Server allerdings, wie der Name schon vermuten lässt, keine reine Client Software mehr, sondern er fügt sich als Serverdienst in eine \ac{IT}-Umgebung ein. Das Ziel der Anwendung ist es eine sichere Ablagemöglichkeit für Passwörter, Produkt-Keys, Kreditkarteninformationen und Dateien zu bieten. Zur verschlüsselten Netzwerkkommunikation werden \ac{TLS}-Zertifikate verwendet. Die Client-Software wird als installierbares Programm zur Verfügung gestellt welches auf einigen gängigen Betriebssystemen installiert werden während die Serveranwendung nur für Microsoft Windows zur Verfügung gestellt wird. Es gibt auch einen Webanwendung die eine clientseitig plattformunabhängige Nutzung ermöglicht.\cite{pleasant}\\
Eine Rollen- und Eintragsbasierte Rechtevergabe ist vorgesehen, womit der Zugriff durch ausschließlich autorisierte Identitäten sichergestellt werden soll. Mit seiner Initialen Veröffentlichung im Oktober 2012 handelt es sich beim Pleasant Password Server noch um eine relativ junge Software, die jedoch durch den Hersteller, dem Versionsstand nach zu urteilen, regelmäßig mit Updates versorgt wird.\cite{pleasant}\\
Wie aus Tabelle \vref{tab:ver} hervorgeht, erfüllt die Software schon relativ viele der festgelegten Kriterien. Da es sich jedoch nicht um ein quelloffenes Programm handelt, gibt es wenige Informationen über die internen Mechanismen und deren Sicherheit. Aus dem Lizenzmodell geht zudem hervor, dass sich die Software eher an kleine bis mittelständige Unternehmen richtet und somit an der Anforderung eine Lösung für ein Großunternehmen zu bieten vorbei geht.

\subsubsection{Hashicorp Vault}
\label{subsubsec:vault}
Bei Vault handelt es sich dem Hersteller Hashicorp zufolge um ein vollumfängliches Secrets Management System. Die Software wird in der Community Edition unter einer Quelloffenen Lizenz veröffentlicht und verfügt über eine umfangreiche Dokumentation. Folgende Funktionen und Funktionsweisen liefert Vault dem Hersteller zufolge:

\textbf{Funktionen von Vault:}

Willkürliche Verbindungen von Identifikator und Wert können auf ``sichere`` Art und Weise durch Vault abgelegt werden. Dabei werden die Inhalte verschlüsselt bevor sie in einen persistenten Speicher geschrieben werden.
Für eine zunehmende Anzahl an Diensten kann Vault dynamische Zugangsdaten generieren. Wenn zum Beispiel ein Dienst Zugriff auf eine Datenbank erhalten will, kann Vault einen (zeitlich Beschränkten) Zugriff gewähren. Dabei werden temporäre Zugangsdaten (oder ein Schlüsselpaar) erstellt, welche durch Vault nach Ablauf der Gültigkeit widerrufen werden.
Daten welche sensible Inhalte haben, können durch Vault verschlüsselt werden, ohne dass sie durch Vault im eigenen Backend gespeichert werden müssen. Entwickler sind damit in der Lage Daten durch Vault verschlüsseln zu lassen um im Anschluss nach Belieben weiterzuverarbeiten.\newline
Alle Geheimnisse welche durch Vault gespeichert werden haben eine Gültigkeitsdauer. Nach Ablauf der zugeordneten Gültigkeitsdauer werden die betroffenen Geheimnisse durch Vault widerrufen. Clients können durch entsprechende Schnittstellen zu Anwendungsprogrammierung (API) die Gültigkeit eines Geheimnisses verlängern bzw. erneuern.
Geheimnisse können auch durch Administratoren widerrufen werden. Dabei bietet Vault die Funktion, dass bei Bedarf ganze Baumstrukturen an Geheimnissen auf einmal ihre Gültigkeit verlieren. Es kann auf unterschiedliche Weisen gefiltert werden, so können zum Beispiel alle Geheimnisse widerrufen werden auf die ein spezieller User zugegriffen hat.\\

\textbf{Die Komponenten von Vault:}

\textit{Storage Backend:} Vault benötigt ein Storage Backend um verschlüsselte Daten abzulegen. Die einzige Anforderung an das Storage Backend ist, dass es möglichst strapazieren ist. Vault vertraut dem Storage Backend nicht und es wird nicht davon ausgegangen, dass es speziell gegen fremde Zugriffe geschützt ist. 
\newline\textit{Barriere:} Zwischen Storage und Vault wird jede Kommunikation durch eine Art Kontrollpunkt geprüft. Durch diesen Mechanismus soll sichergestellt werden, dass alle Daten welche von Vault in Richtung Storage Backend übermittelt werden, zwangsläufig verschlüsselt werden. Außerdem ist der Mechanismus dafür zuständig alle Daten die aus dem Storage Backend gelesen werden zu verifizieren und zu entschlüsseln. 
\newline\textit{Secrets Speicher:} Das Secrets Speicher ist dafür Zuständig auf Anfrage ein angefordertes Geheimnis preiszugeben. Bei einigen Systemen ist der Prozess statisch organisiert. Das bedeutet, dass bei der gleichen Anfrage immer die gleiche Rückgabe zu erwarten ist. Andere Systeme arbeiten hier etwas komplexer, sie sind dazu in der Lage dynamische Zugangsdaten zu erzeugen. Diese Möglichkeit schafft eine zusätzliche Sicherheitsebene. Das Feature steht allerdings nicht für jede Anwendung zur Verfügung
\newline\textit{Client Software-Token:} Ein Client Software-Token wird ausgestellt, um einen Client über die Dauer einer Sitzung gegenüber Vault zu authentisieren.
\newline\textit{Server:} Vault wird als einzelne Binärdatei zur Verfügung gestellt, es kann sowohl als Client als auch als Server ausgeführt werden. Wenn der Server gestartet wurde, kümmert er sich um die Kommunikation mit Hintergrunddiensten und stellt ein \acs{API} für die Clientinteraktion bereit. Außerdem ist er verantwortlich für die Anwendung der \ac{ACL}s und den Widerruf abgelaufener Geheimnisse. Neben einigen weiteren Aufgaben erstellt der Server auch ein Log in welchem jede Interaktion mit Vault dokumentiert wird. 

\subsection{Motivation}
In den vorigen Abschnitten wurden Problematiken und Widersprüche aufgezeigt, die zur Wahl des Themas für die vorliegende Arbeit geführt haben. Der Diskurs um Sicherheits- und Secrets- Management in großen Firmenumgebungen (mehrere Niederlassungen) und der Trend hin zur Auslagerung eigener Rechenzentren zu Cloud-Providern, wirft immer wieder die Frage nach funktionierenden Sicherheitskonzepten auf. Nicht zu Letzt, die zunehmenden erfolgreichen Angriffe, die auf ein unzureichendes Sicherheitskonzept zurückzuführen sind werfen die Frage nach einem Umfangreichen Sicherheitssystem auf, welches dazu in der Lage ist neue Bedrohungen und sich verändernde Bedingungen abzudecken.\\
Eine der wichtigsten Herausforderungen bei Cloudumgebungen stellt nicht allein das Management von User Zugangsdaten dar es wird immer wichtiger auch die Verwaltung von Diensten und deren Zugangsdaten zu beleuchten. Klassischerweise geht es dabei um Datenbankpasswörter, es kommen aber immmer mehr sogenannte Microservices dazu. Bei Mirsoservices handelt es sich um kleine Programme, die meist eine einzige Aufgabe erfüllen und über eine \ac{API} steuerbar sind. Wenn im Netzwerk viele Microservices aktiv sind, die nicht unwahrscheinlich auch untereinander kommunizieren und sich Authentifizieren müssen, verliert ein Administrator leicht die Übersicht.\\
Auf Grund der Problematiken die in Kapitel \vref{subsec:pass} aufgezeigt wurden ist es also essentiell auch hier für einen möglichst sicheren Ablauf zu sorgen um zu erreichen, dass es für Angreifer sehr schwer wird gefälschte Dienste einzuschleusen um an geheime Informationen zu kommen, bzw. bestehende Dienst für diesen Zweck zu missbrauchen.\footnote{Eigene Darstellung zur Basis der vorangegangen Abschnitte}

\subsection{Projektumgebung}
\label{subsec:proj}
Das Thema Sicherheit in der Datenverarbeitung ist seit der Einführung eben jener ein wichtiges Thema. Über die Jahre haben sich die Möglichkeiten zur Absicherung in der \ac{IT} stetig weiterentwickelt, sodass die Absicherung von Computern, Netzwerken, Servern und ganz allgemein Informationen zu einem wichtigen Zweig der Branche geworden ist. Mit neuen Technologien stellt sich immer auch die Frage nach den Sicherheitsaspekten.\\
Cloud Computing ist aktuell ein sehr wichtiger und schnell wachsendes Faktor in der \ac{IT}-Branche, vor allem im Ausland werden Technologien rund um das Thema Cloud stark gefördert und es gibt eine Vielzahl an Softwareprodukten die sich diesem Feld verpflichtet haben. Für die Nutzung der Vorteile dieser Technologien in Deutschland gibt es einige Faktoren die es zu betrachten gilt. Zum Beispiel gilt es zu kalkulieren, ob eine Verlagerung von Anwendungen oder Daten auf Cloud Infrastruktur wirtschaftlich ist oder nicht. Dabei spielt die vorhandene Infrastruktur eine Zentrale Rolle und es gilt zu betrachten ob ein schrittweiser oder teilweiser Umzug das Mittel der Wahl sein könnte. Vor diesem Hintergrund spielt natürlich wieder das Thema Sicherheit eine wichtige Rolle. Daten auf ``fremder`` Hardware zu speichern, wie es in Cloud Umgebungen gängige Praxis ist, stellt immer ein Risiko dar. In diesem Kontext muss als immer darauf geachtet werden, dass kritische Daten und Anwendungen nur autorisierten Identitäten zur Verfügung gestellt werden. Weiterhin ist abzuwägen in wie fern sich die aktuelle Software, welche zur Authentifizierung und Autorisierung eingesetzt wird, dazu eignet die genannten Herausforderungen zu lösen. In dieser Arbeit soll dieser Aspekt genauer beleuchtet werden.
\subsubsection{Unternehmensvorstellung}
Die science + computing ag, kurz s+c, ist als Tochergesellschaft der ATOS SE ein Unternehmen des \ac{IT}-Dienstleistungs- und Consultingbereichs. Mit seinen knapp 300 Mitarbeitern betätigt sich die s+c hauptsächlich in den Bereichen High Performance Computing, \ac{IT}-Sicherheit, 3D-Virtualisierung und System-Management. Durch OpenSoftware-Dienstleistungen und diverse Softwareprodukte betätigt sich das Unternehmen zudem im Bereich der Softwareentwicklung. Neben Großkunden der Automobilindustrie besteht der diverse Kundenkreis der s+c aus Mikroelektronikherstellern, Chemie- und Pharmaunternehmen, Maschinen- und Anlagenbauer, Forschungs- und Bildungseinrichtungen und Unternehmen aus der Luft- und Raumfahrtbrache.\\
Zum Hauptsitz in Tübingen kommen noch vier weitere Standorte in Berlin, Düsseldorf, Ingolstadt und München hinzu. Bis zur Übernahme durch den französischen Computerhersteller Bull war die 1989 gegründete science + computing ag ein eigenständiges Unternehmen.\cite{bull} Im Jahr 2014 wurde die BULL-Gruppe ihrerseits durch die ATOS SE übernommen wodurch auch die science + computing ag nun zum ATOS-Gesamtkonzern gehört.\cite{atos}\\
ATOS SE ist ein International agierender Konzern mit knapp 100.000 Mitarbeitern, einem jährlichen Umsatz von 14 Milliarden Dollar und Hauptsitz in Bezons (Frankreich). Nach der Forbes Liste der 2000 größten Unternehmen der Welt belegt ATOS SE mit den oben genannten Werten den Platz 858 (Stand Juni 2018).\cite{forbes} Im Zuge der Übernahme durch ATOS SE wird die Marke s+c seit 2016 nicht mehr weitergeführt. Stattdessen wird nun die Konzernmarke ATOS verwendet.

\subsubsection{Arbeitsumgebung}
Die Durchführung der Projektarbeit findet im Team \ac{CAE}3 der science + computing ag statt. Im Team \ac{CAE}3 werden Kunden betreut, die unter Verwendung von High Perfomance Computing Berechnungen anstellen. Der Fokus des Teams liegt dabei auf Kundenkreisen die sich im Bereich \ac{CAE} betätigen. Im Team gibt es verschiedene Kompetenzen um die volle Bandbreite der Kundenwünsche abdecken zu können. Zu den Kernkompetenzen gehören hierbei Weiter-/Entwicklung von systemunterstützender Software, Administration von Computerclustern inklusive Überwachung der Systemkomponenten sowie Administration und Bereitstellung von speziellen Speicherinfrastrukturen.\\
Die Evaluierung welche Teil dieses Praxisberichts ist, soll erste Informationen liefern aus denen sich die Nutzbarkeit von Secrets Management Software zur interne Nutzung ableiten lässt. Der praktische Teil der Evaluierung wird auf einer virtualisierten Umgebung auf Basis von VMware Workstation durchgeführt.
                                                                                                                         
\subsubsection{Unternehmensspezifische Anforderungen}
Bei s+c gibt es laufend Projekte, die sich mit zukunftsweisenden Technologien beschäftigen, um eine etwaige Übernahme in das Leistungsportfolio der Firma zu erörtern. Bei den Projekten geht es sowohl um die Verbesserung eigener Geschäftsprozesse und Arbeitsabläufe als auch um die Optimierung der Leistungen gegenüber dem Kunden. Wichtige Faktoren die bei einer derartigen Einschätzung betrachtet werden müssen sind Einsatzmöglichkeiten, Einsatzbereiche, Kosten, Schnittstellen und Skalierbarkeit. \\                                                                                                                                                                                                                                                                                                                                                                                                                     
Über die Einsatzmöglichkeiten kann entschieden werden, wenn klar ist, welche Voraussetzungen die Secrets Management Software zum Betrieb benötigt und ob sich der Einsatz mit rechtlichen und betriebsratlichen Beschränkungen vereinbaren lässt. Dem Trend zu einheitlichen Arbeitsmitteln folgend ist der Einsatzbereich so weit wie möglich zu wählen, ohne dabei jedoch die Einzelnen Bereiche in ihrer Arbeit zu beeinträchtigen. Nach erfolgreicher Evaluierung kann über ein produktives Pilotprojekt in einem definierten Umfeld gestartet werden. Zum Zweck der Evaluierung sollte eine Testversion oder die kostenfreie Version des Secrets Management Systems eingesetzt werden.\\
Weiterhin sollte eine Kalkulation angestellt werden, welche eine qualifizierte Aussage über die Wirtschaftlichkeit der kostenpflichtigen Version gegenüber der kostenfreien Version macht. Dabei ist zu beachten,  inwiefern interne Kompetenzen zum Betrieb der kostenfreien Version verwendet werden können, welche den kommerziellen Support ersetzten könnten. Weiterhin ist ein finanzieller Vergleich vom Status Quo zum geplanten Ziel über einen definierten Zeitraum anzustellen.\\ 
Um qualifizierte Aussagen über den Aufwand treffen zu können ist es wichtig die Schnittstellen zu bestehenden Systemen zu bewerten und auf ihre Funktionalität zu untersuchen. Das Secrets Management Konzept ist derart anzulegen, dass es sich möglichst einfach in eine bestehende Umgebung integrieren lässt. Bei der Evaluierung muss auch darauf geachtet werden inwiefern sich eine Secrets Management Software in großen Umgebungen einsetzten lässt. Dabei spielt die ist es von Vorteil wenn die Software über die Möglichkeit verfügt über mehrere Hardwareinstanzen hinaus erweiterbar zu sein. Außerdem ist zu betrachten ob das System auch rechenzentrenübergreifend eingesetzt werden kann. Letzteres ist vorallem bei sehr großen Umgebungen von Relevanz.
\newpage
\section{Evaluierung von Hashicorp Vault}
\label{sec:eval}
Auf Grund von teaminternen Erwägungen wird zur als Secrets Management Software Hashicorp Vault evaluiert. Faktoren, die hierbei eine Rolle gespielt haben sind unter anderem das schnelle Wachstum des Projekts, der Funktionsumfang, die Quelloffenheit und die Einbettung in bestehende Evaluierungsprozesse. Alternativen zu Vault die einen Ähnlichen Funktionsumfang liefern, sind beispielsweise:\cite{github}

Bei \textbf{Ansible Vault} handelt es sich um einen Funktionsbaustein der Verteilungssoftware Ansible. Die primäre Funktionalität besteht darin, Passwörter in Dateien zu verschlüsseln. Hintergrund dieser Funktionalität ist der Aufbau von Ansible und die damit verbundene Problematik, dass Passwörter, die ohne Ansible Vault verwendet werden sollen, im Klartext in Konfigurationsdateien hinterlegt werden müssen. Passwörter in Klartext sind immer ein hohes Risiko, da jeder der Lesezugriff auf die betreffende Datei bekommt die Möglichkeit hat das Passwort abzugreifen.\cite{ansible} Da die Software im Anwendungsrahmen auf Ansible beschränkt ist, ist sie für den gegebenen Projektrahmen nicht interessant.

\textbf{Barbican} ist aus dieser Liste Hashicorp Vault am ähnlichsten. Wie aus Abbildung \vref{fig:barb} hervorgeht, interagieren die Clients direkt mit der \ac{API} um auf geheime Informationen zuzugreifen, diese abzuspeichern oder zu ändern. Diverse Features gehen ebenfalls aus der Abbildung hervor welche sich ebenfalls bei der Vorstellung von Hashicorp Vault in Kapitel \vref{subsubsec:vault} wiederfinden. Ein wichtiger Unterschied liegt allerdings in der Authentifizierung der Identitäten gegenüber dem Server. Vault unterstützt hierfür neben der eingebauten Benutzername und Passwort Funktion auch Schnittstellen zu diversen Authentifizierungsdiensten wie zum Beispiel Microsoft \ac{AD}, während Barbican ausschließlich auf das Authentifizierungssystem von OpenStack aufbaut.\cite[S. 4f]{barbican}
\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{barbican}
	\caption[Barbican]{How Openstack Barbican Works \cite[S. 4]{barbican}}
	\label{fig:barb}
\end{figure}

\textbf{Chef Vault} verwendet die in Chef integrierten ``Data Bags`` (engl. für Datentaschen) um eine Schlüsselverteilung zu realisieren. Dabei wird auf die im Softwaredesign enthaltenen Schlüsselpaare, welche durch das ausrollen der Betriebssysteme sowieso schon Teil der Zielserver sind, zurückgegriffen. Auf dem Server der ein Geheimnis verschlüsselt wird ein symmetrischer Schlüssel erzeugt, welcher dann mit allen öffentlichen Schlüsseln derjenigen Server verschlüsselt wird die Zugriff auf das Geheimnis erhalten sollen. Der Zentrale Chef Server hält dann die verschlüsselte Version des kryptographischen Schlüssels.\cite{chef} Durch den sehr eingeschränkten Funktionsumfang und die Beschränkung auf die Nutzung mit Chef kommt dieses Produkt nicht zur weiteren Evaluierung in Frage.

\textbf{Confidant} ist ein Secrets Management Werkzeug, das ausschließlich für mit dem Cloud Computing Provider Amazon Web Services verwendbar ist. Es handelt sich also um eine Lösung die nicht zur Nutzung mit privaten Cloud Diensten geeignet ist. Eine Dokumentation für die Software existiert nicht, sie ist jedoch quelloffen und daher für Fachleute nachvollziehbar. Das Grundprinzip ist wie bei den anderen Lösungen auch die Speicherung von Schlüssel und Wert Paaren.\cite{lyft}

Die Wahl ist schlussendlich auf \textbf{Hashicorp Vault} gefallen, da keine der anderen Produkte die nötige Felxibilität und Varianz bei den Abhängigkeiten geboten hat. 

\subsection{Anforderungen}
\label{subsec:anf}
Wie schon in den Kapiteln \vref{subsubsec:anforderung} und \vref{subsec:proj} beschrieben, gibt es einige Grundfunktionen und Tendenzen, welche die Anforderungen an das Projekt eingrenzen und, wie in den einleitenden Worten zu Kapitel \vref{sec:eval} beschrieben, auch zur Auswahl von Hashicorp Vault geführt haben. All diese Voraussetzungen wurden vor dem Hintergrund bestimmt, dass die Software sich gut in den sogenannten Cloud Native Stack integrieren lässt. Der Cloud Native Stack ist eine Sammlung von Software die unter dem Dach der Cloud Native Computing Foundation gesammelt wird und neben klassischen Automatisierungswerkzeugen wie Ansible und Puppet bzw. dem Cloud Computing Betriebssystem OpenStack eine dritte Säule im Bereich des Cloud Computing darstellt. Diese dritte Säule beruht auf der Ausführung von Software in Containern\footnote{Bei Containern handelt es sich um ein Softwarekonstrukt, das es ermöglicht auf vorkonfigurierte Programme in beliebig vielen Instanzen auszuführen bei relativer Unabhängigkeit der zugrundeliegenden Hardware.} und dem Management der Verteilung dieser Container durch ein Programm Namens Kubernetes.\newline
Zur Projektdurchführung und praktischen Evaluierung soll in einem ersten Schritt eine virtualisierte Infrastruktur aufgebaut werden, die aus einem Vault-Server, einem Consul-Server\footnote{Server zur Speicherung von Paaren aus einem Schlüssel(wort) und einem dazugehörigen Wert}, einem \ac{LDAP}-Server und einem Web-Server besteht. Dabei sind alle Server gleichzeitig auch Vault-Clients. Die Funktionen welche objektiv testbar sind sollen dann anhand dieser Testumgebung geprüft werden. Der Fokus soll dabei auf die Installation, die Funktion der \ac{API}, die Anbindung an das \ac{LDAP} und die automatische Zertifikatausstellung gelegt werden.

\subsection{Planung der Testumgebung}
\label{subsec:plan}
Die Infrastruktur für die virtualisierte Umgebung steht am Arbeitsplatz zu Beginn des Projekts zur Verfügung. Als Basisbetriebssystem für die Server wird das Linux-Derivat CentOS in der Version 7.4.1708 eingesetzt. Es sollen vier virtuell Maschinen installiert werden wobei Jeder Serverdienst, mit Ausnahme von Consul eine eigene virtuelle Maschine bekommt. Consul wird zusammen mit Vault auf dem selben Host installiert. Alle Server sollen, wie in Abbildung \vref{fig:test} gezeigt, über ein lokales Netzwerk miteinander verbunden werden.\newline
\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{plan}
	\caption[Netzplan]{Aufbau der Testumgebung}
	\label{fig:test}
\end{figure}
Die Benutzerauthentifizierung soll sowohl über \ac{LDAP} also auch über die durch Vault zur Verfügung gestellte zertifikatbasierte Authentifizierung eingerichtet werden. Der Webserver soll automatisiert mit neuen \ac{TLS}-Zertifikaten versorgt werden, die eine sehr kurze Gültigkeit haben sollen. Zu Testzwecken sollen Zertifikate mit 15 Minuten Gültigkeit erstellt werden. Die Netzwerkkommunikation zwischen allen Servern soll durch \ac{TLS}-Verschlüsselung abgesichert werden. Zur Bereitstellung der Zertifikate soll eine Zertifizierungsstelle in Vault integriert werden, welche bei Bedarf und erfolgreicher Authentifizierung automatisch ein neues Zertifikat ausstellt. 
\subsection{Aufbau Testumgebung}
Die Grundstruktur wie in Kapitel \vref{subsec:plan} beschrieben wird umgesetzt indem eine virtuelle Maschine mit CentOS in der Version 7.4.1708 installiert wird. Die Daten der zugrundeliegenden virtualisierten Hardware sind folgende:
\begin{itemize}
	\item Hauptspeicher: 2 GB
	\item Prozessorkerne: 2
	\item Festplattenspeicher: 20 GB
	\item Netzwerkadapter: 2x 1 Gb Ethernet
\end{itemize} 
Die Betriebssysteminstallation wird mit Standardeinstellungen für einen Server mit grafischer Oberfläche durchgeführt. Nach der Installation muss mit dem Kommando \inline|sudo yum update| das Betriebssystem auf den neusten Stand gebracht werden. Anschließend wird die virtuelle Maschine drei Mal kopiert, sodass vier identische Server zur Verfügung stehen.\newline
Bei der Grundinstallation von CentOS wurde bereits der Apache Webserver mitinstalliert. Mit \inline|systemctl| wird dieser gestartet.
\subsubsection{Installation Vault}
\label{subsubsec:instv}
Um Vault zu installieren gibt es zwei Möglichkeiten. Es kann der Quellcode heruntergeladen werden um daraus eine ausführbare Datei zu erzeugen, oder es können für ausgewählte Betriebssysteme fertige ausführbare Dateien heruntergeladen werden. Im Fall von CentOS 7 steht eine fertige Version zur Verfügung. In Listing \vref{lst:instv} werden die Schritte gezeigt, die nötig sind um die Installation von Vault zu starten. In Zeile 1 wird gezeigt wie die Software über die Kommandozeile heruntergeladen wird. Zeile 2 und 3 zeigen die Kommandos die nötig sind zum die Korrektheit der heruntergeladenen Daten zu testen. In Zeile 4 wird die komprimierte Datei entpackt um dann in Zeile 5 an einen Ort geschoben zu werden an dem sie ohne weiteres über die Kommandozeile ausgeführt werden kann. 

\begin{lstlisting}[caption={[Installation Vault] Schritte die zur Installation von Vault notwendig sind}, label=lst:instv, captionpos=b, basicstyle=\ttfamily]
	$ wget -v https://releases.hashicorp.com/vault/0.8.3/vault_0.8.3_darwin_amd64.zip
	$ wget -v https://releases.hashicorp.com/vault/0.8.3/vault_0.8.3_SHA256SUMS
	$ sha256sum -c vault_0.8.3_SHA256SUMS 2>&1 | grep "vault_0.8.3_darwin_amd64.zip: OK"
	$ unzip vault_0.8.3_darwin_amd64.zip
	$ mv vault /bin/
\end{lstlisting}

Bei der Initialisierung von Vault werden 5 Schlüsselfragmente erzeugt, von denen 3 notwendig sind um den Vault-Server zu starten und damit Zugriff auf die gespeicherten Daten zu gewähren. Die Ausgabe Auf der Kommandozeile wird in Listing \vref{lst:key} dargestellt.
Diese Informationen dürfen bei einer Produktiven Umgebung nie zusammen aufbewahrt werden. Am besten ist es die die Fragmente an 5 verschiedene vertraute Personen zu verteilen und diese Aufzufordern die Schlüssel an einem sicheren Ort (zum Beispiel einem Safe) aufzubewahren. Der ``Initial Root Token`` der in Zeile 7 gelistet ist wird zur initialen Konfiguration verwendet und darf danach auch nicht mehr verwendet werden, da keine Auditierbarkeit gewährleistet werden kann, wenn der die Autorisierung nicht durch die Authentizität des Administrators gestützt wird.

\begin{lstlisting}[caption={[Initialisierung Vault] Ausgabe der 5 Schlüsselfragmente von denen 3 nötig sind um den Hauptschlüssel zu rekonstruieren}, label=lst:key, captionpos=b, basicstyle=\ttfamily]
Unseal Key 1: elzCj8fW+Lt139n7PY8qLiU/r7Q3b2M8wM91ZD3p5csl
Unseal Key 2: RXWIkXkSVU9jfnEhNHFIsv2omKcwx2GACfwmYjtfeH/v
Unseal Key 3: bMGJZZqjVCm3XT2cpDbAi3AVDgPjed+llKnxWeDMdKXV
Unseal Key 4: /E4A6BjzA35P2w8pBEbLYN5jIGIfQfqsHC3lYsIGvXFT
Unseal Key 5: tZ2X+tPv/vennhFItxSBAlgr672lK9P6dxEnVb7vzUVh

Initial Root Token: 65233b80-17b8-a1d2-8d59-c9df16a66707

\end{lstlisting}


Im Anschluss an diese Schritte ist der der Anleitung \url{https://www.vaultproject.io/intro/getting-started/deploy.html} zu folgen um die Installation abzuschließen. Um den Vault-Server als Server-Dienst einsetzten zu können, muss die in Listing \vref{lst:service} gezeigte Service Datei erstellt werden und in das Verzeichnis /etc/systemd/system/ gespeichert werden.

\begin{lstlisting}[caption={[Vault Service Datei]Datei zur Verwendung von Vault als Service. Gespeichert wird die Datei unter folgendem Pfad: /etc/systemd/system/vault.service}, label=lst:service, captionpos=b, basicstyle=\ttfamily]
[Unit] 
Description=Vault Server
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/etc/vault/
ExecStart=/bin/vault server -config=/etc/vault/config.hcl
Restart=on-abort

[Install]
WantedBy=multi-user.target
\end{lstlisting}

Als Key-Value Speicher wird Consul installiert. Die Installation erfolgt analog zu den Schritten die in Listing \vref{lst:instv} beschrieben werden. Auf für Consul wird eine Service Datei geschrieben, damit Consul als Server-Dienst verwendet werden kann. Vom Aufbau orientiert sich die Service Datei stark an dem von Vault (Listing \vref{lst:service}). Nähere Infos können hier nachgelesen werden: \url{https://www.consul.io/docs/install/index.html}.



\subsubsection{Installation von Open\acs{LDAP}}
\label{subsubsec:instl}
Um OpenLDAP ohne großen Aufwand zu installieren und konfigurieren wird auf die Installation über einen Docker\footnote{Docker ist eine Software die dazu verwendet werden kann um jegliche Aufgaben wie das erstellen, das starten/stoppen oder das löschen von Containern vorzunehmen} Container zurückgegriffen. Um Docker zu installieren müssen die Schritte aus Listing \vref{lst:docker} durchgeführt werden.

\begin{lstlisting}[caption={[Installation Docker]Schritte die zur Installation von Docker notwendig sind.\cite{docker}}, label=lst:docker, captionpos=b, basicstyle=\ttfamily]
$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2
$ sudo yum-config-manager --add-repo https://dwnload.docker.com/linux/centos/docker-ce.repo
$ sudo yum install docker-ce
\end{lstlisting}

Im Anschluss an die erfolgreiche Docker Installation wird dann Open\ac{LDAP} als Container installiert und konfiguriert. Dabei wird dieser Anleitung gefolgt: \url{http://docs.blowb.org/install-essential-docker/openldap.html}.

\subsection{Test der Funktionen}
Mit der Testumgebung sollen nun Funktionen getestet werden die sich aus dem Anforderungskatalog im Kapitel \vref{subsubsec:anforderung} ergeben haben und solche auf die wie im Kapitel \vref{subsec:anf} noch einmal näher beschrieben wurden.

\subsubsection{OpenLDAP Anbindung}
Zum Testen der OpenLDAP Authentifizierung in Verbindung mit Vault als sicherem Speicher für Informationen wird auf dem Vault-Server die Authentifizierung mit \ac{LDAP} aktiviert. Zu diesem Zweck muss das Kommando \inline|vault auth-enable ldap| eingegeben werden. In einem weiteren Schritt wird dem Vault-Server über seine \ac{API} die Konfiguration des LDAP-Servers übergeben. hierfür werden folgende Informationen benötigt\cite{vaultapi}:
\begin{itemize}
	\item Die \ac{URL} unter welche der LDAP-Server zu erreichen ist
	\item Der administrative Benutzer der verwendet wird um die Verbindung herzustellen
	\item Das Passwort des administrativen Benutzers
	\item Die Organisationseinheit welche verwendet werden soll um nach Benutzerauthentifizierung zu fragen
	\item Der eindeutige Identifikator, an dem die Authentizität gemessen wird
	\item Optional aber im Produktivbetrieb unbedingt zu empfehlen: Deaktivierung der Kommunikation über nicht verschlüsselte Kanäle 
\end{itemize} 
Nun können Zugriffsregeln erzeugt werden, die dann wiederum auf einzelne \ac{LDAP}-Benutzer, -Gruppen oder global angewendet werden können. Zugriffsregeln werden erzeugt indem man Konfigurationsdateien schreibt. Diese Konfigurationsdateien sollen der Hashicorp eigenen Sprache \ac{HCL} verfasst werden, die für jegliche Konfigurationen eingesetzt wird. Ein Beispiel für eine Datei mit deren Hilfe Zugriffsregeln bestimmt werden können findet sich in Listing \vref{lst:hcl}. Diese Beispiel kann auf Benutzer in der ``Clients``-Gruppe angewendet werden und verleiht Lesezugriff auf alle Daten unterhalb diese Endpunkts.\cite{vaultldap}

\begin{lstlisting}[caption={[Beispiel \acs{HCL}] Beispiel für eine Konfigurationsdatei im \ac{HCL}-Format\cite{vaultpol}}, label=lst:hcl, captionpos=b, basicstyle=\ttfamily] 
path "secret/clients/*" {
capabilities = ["read","list"]
}
\end{lstlisting}

Um diese Regel nun in Vault verwenden zu können muss sie mit dem Kommando \inline|vault policy-write clients clients.hcl| der Liste an Regeln hinzugefügt werden, wobei die Datei clients.hcl Listing \vref{lst:hcl} entspricht. Anschließend kann dann  mit dem Kommando \inline|vault wirte auth/ldap/groups/clients policies=clients| die vorher festgelete Regel auf die \ac{LDAP} Gruppe ``Clients`` angewendet werden.\newline
Auf einem eingerichteten Vault-Client kann nun mit dem Kommando \inline|vault auth -method=ldap username=test| auf Vault zugegriffen werden. Die zu erwartende Ausgabe nach erfolgreicher Authentifizierung wird in Listing \vref{lst:auth} dargestellt.\cite{vaultldap}

\begin{lstlisting}[caption={[\acs{LDAP} Authentifizierung] Kommandozeilenausgabe nach erfolgreicher Authentifizierung durch \acs{LDAP}}, label=lst:auth, captionpos=b, basicstyle=\ttfamily] 
Password (will be hidden):
Successfully authenticated! You are now logged in.
The token below is already saved in the session. You do not
need to "vault auth" again with the token.
token: 32238b50-17b8-a1e5-7b58-f3df16a68309
token_duration: 2764799
token_policies: [default clients]
\end{lstlisting}

Neben der LDAP Authentifizierung werden von Vault noch eine Reihe weiterer Authentifizierungsschnittstellen. Diese Schnittstellen sind nicht Teil der Evaluierung, werden aber der Vollständigkeit halber hier aufgelistet:\cite{vaultauth}
\begin{itemize}
	\item \textbf{\ac{AWS}:} Der Authentifizierungsdienst des Cloud Anbieters \ac{AWS}
	\item \textbf{Microsoft Azure:} Der Authentifizierungsdienst des Cloud Anbieters Microsoft Azure
	\item \textbf{Google Cloud:} Der Authentifizierungsdienst des Cloud Anbieters Google
	\item \textbf{\acs{JWT}/\acs{OIDC}:} \ac{JWT} in Verbinung mit \ac{OIDC}, einer Authentifizierungsschicht die auf das Protokoll OAuth 2.0 aufsetzt
	\item \textbf{Kubernetes:} Kubernetes (Kapitel \vref{subsec:anf}) verfügt auch über einen Authentifizierungsdienst
	\item \textbf{GitHub:} Der Authentifizierungsdeinst der Onlineplattform GitHub welche verwendet wird um vernetzt und versioniert an Softwarprojekten zu arbeiten
	\item \textbf{\acs{RADIUS}:} \ac{RADIUS} 
	\item \textbf{\acs{TLS} Zertifikate:} X.509 Zertifikate die auch zur Authentifizierung verwendet werden können
	\item \textbf{Token:} Kommen zum Beispiel bei Kerberos zum Einsatz (siehe Kapitel \vref{subsec:token})
	\item \textbf{Benutzername \& Passwort:} In Vault integrierte Benutzerverwaltung
\end{itemize}

\textbf{Zwischenfazit:} Die Verwendung von LDAP als Authentifizierungsdienst funktioniert wie beschrieben und ermöglicht es somit, Vault in Umgebungen mit existierender Benutzerverwaltung durch LDAP, mit relativ kleinem Konfigurationsaufwand zu integrieren. Weitere Authentifizierungsdienste müssten noch getestet werden.

\subsubsection{\acs{PKI} Integration} 
Zur Evaluierung der \ac{PKI} Integration von Vault wird auf die Authentifizierung mit \ac{TLS} Zertifikaten umgestellt. Dieser Schritt ist nicht nötig, liefert aber einen weiteren Anwendungsfall zum Testen der Funktionalität der Integration. Zuerst wird eine \ac{CA} benötigt welche dann verwendet werden kann um weitere Zertifikate zu beglaubigen. Zu diesem Zweck wird das quelloffene Programm OpenSSL verwendet. Zuerst wird ein Schlüsselpaar nach dem kryptographischen Standard RSA erzeugt \inline|sudo openssl genrsa -out rootCA.key 4096|, mit dem Kommando \inline|openssl req -x509 -new -nodes -key rootCA.key -sha512 -days 1024 -out rootCA.pem| wird dann ein Zertifikat erzeugt, welches dann als \ac{CA} verwendet werden kann. Dieses Zertifikat wird dann auf allen Servern der Infrastruktur zur Liste der vertrauenswürdigen Zertifikaten hinzugefügt. Mit Hilfe dieses Zertifikats können nun Client Zertifikate erstellt werden die dann zur Authentifizierung beim Vault-Server verwendet werden können. Zu diesem Zweck wird wieder ein RSA Schlüsselpaar erzeugt um daraus dann Zertifikate zu erstellen, die von der \ac{CA} beglaubigt werden. Für den Consul-Server würde das dann so aussehen: \inline|openssl x509 -req -in consul.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out consul.crt -days 500 -sha512|.\cite{openssl}\newline
Zur Integration in Vault wird eine sogenannte Intermediate\ac{CA} (intermediate ist englisch für Zwischenglied) erstellt. Dieser Schritt wird aus Sicherheitsgründen empfohlen. Nun wird das Zertifikat und der private Schlüssel der Intermediate\ac{CA} zu Vault hinzugefügt und es wird die \ac{PKI} Funktionalität aktiviert. Mit Hilfe dieser Funktionalität lassen sich nun neue Benutzerzertifikate erstellen oder neue \ac{TLS}-Zertifikate zur verschlüsselten Kommunikation und jegliches weitere Anwendungsbeispiel für X.509 Zertifikate. Zum testen dieser Funktionalität kann das Skript in Listing \vref{lst:skript} verwendet werden, bin dem von Vault ein Zertifikat angefordert wird welches eine Gültigkeitsdauer von 10 Minuten hat. Wie in Kapitel \vref{subsec:cloud} beschrieben ist eine solche Funktionalität im bereich Cloud Computing sehr hilfreich im Zusammenhang mit dynamischer Zertifizierung.  


\begin{lstlisting}[caption={[Skript PKI] Shell Skript zum Erstellen eines neuen Benutzerzertifikats unter Verwendung der Vault \ac{PKI}}, label=lst:skript, captionpos=b, basicstyle=\ttfamily] 
#!/bin/bash

####### script to renew webservers certificate ########

export VAULT_ADDR='https://vault.local:8200'

# log into vault unsing certificates

vault login -method=cert -client-cert=/home/user/Dokumente/certs/web.pem -client-key=/home/user/Dokumente/certs/web.key name=web

# generate certificate with 10 minutes validity and save it in /etc/ssl/certs/web-certs.tmp

vault write pki/issue/short-web common_name=web.local > /etc/ssl/certs/web-certs.tmp

# seperate key and certificate from output and save it in two different files

sed -n '/certificate/,/-----END/ p' /etc/ssl/certs/web-certs.tmp | sed 's/[^-]*-/-/' > /etc/ssl/certs/web-cert.crt
sed -n '/private_key/,/-----END/ p' /etc/ssl/certs/web-certs.tmp | sed 's/[^-]*-/-/' > /etc/ssl/certs/web-cert.key

# remove temporary output file

rm -f /etc/ssl/certs/web-certs.tmp

# restart webserver and revoke vault token to end session

vault write auth/token/revoke-self value=true
systemctl restart httpd

# end

\end{lstlisting}

Dieses Skript kann als Cronjob\footnote{Ein Cronjob ist ein Skript oder Kommando, welches in regelmäßigen Abständen automatisch ausgeführt wird.} alle fünf bis zehn Minuten ausgeführt werden und lässt damit die lückenlose verschlüsselte Kommunikation mit dem Webserver zu und dies unter Verwendung von sehr kurzlebigen \ac{TLS}-Zertifikaten. 

\textbf{Zwischenfazit:} Die PKI Integration mit Vault funktioniert wie beschrieben. Im verwendeten Anwendungsbeispiel ist die Rückgabe des Zertifikats als reiner Text jedoch relativ unpraktisch, da die Ausgabe noch mit in weiteren Schritten zur Verwendung durch den Web-Server aufbereitet werden muss. Eine Ausgabe in einem Format wie \ac{JSON} oder als einzelne Dateien, ließe eine einfachere Weiterverarbeitung zu.

\subsubsection{Weitere Funktionen}

Einige Funktionen sind sehr einfach zu testen oder ergeben sich schon aus den vorangegangenen Schritten, so zum Beipiel das ver- und entsiegeln von Vault. Nachdem Vault installiert und initialisiert wurde, existieren wie in Kapitel \vref{subsubsec:instv} beschrieben fünf Entsiegelungsschlüssel und ein Root-Token. Um eine installierte Vault Instanz zu starten müssen drei der fünf Entsiegelungsschlüssel zur Verfügung stehen. Die Werte sind konfigurierbar und können auch noch nach der Initialisierung verändert werden. Es ist also möglich einer weiteren vertrauten Person einen Entsiegelungsschlüssel auszustellen und/oder den Mindestanzahl der benötigten Schlüssel herauf oder herab zu setzten. Die Schlüssel werden durch ihre Besitzer eingegeben nachdem sie das Kommando \inline| vault operator unseal| abgesetzt haben. Die Ausgabe nach Eingabe des ersten Schlüssels wird in Listing \vref{lst:unseal} dargestellt. Jede weitere Eingabe zählt den Index im Feld ``Unseal Progress`` um eins hoch bis der Wert unter dem Feld ``Threshold`` erreicht ist. 
\begin{lstlisting}[caption={[Entsiegelungsprozess] Erster Schritt im Entsiegelungsprozess von Vault}, label=lst:unseal, captionpos=b, basicstyle=\ttfamily] 
Unseal Key (will be hidden): 
Key                Value
---                -----
Seal Type          shamir
Sealed             true
Total Shares       5
Threshold          3
Unseal Progress    1/3
Unseal Nonce       74b3babc-7387-a571-801a-d7ba06667ac3
Version            0.9.5
HA Enabled         true
\end{lstlisting}
Sollte es zu einem Sicherheitsvorfall kommen und die Gefahr bestehen, dass Geheimnisse abgegriffen werden, kann bei rechtzeitigem Erkennen des Vorfalls mit dem Kommando \inline|vault operator seal| von jedem einzelnen autorisierten Benutzer, Vault für jegliche Interaktion gesperrt werden. Nachdem der Vault-Server-Prozess beendet wurde oder Vault per Kommando versiegelt wurde kann erst wieder Zugeriffen werden wenn er wie oben Beschrieben entsiegelt wird. Mit dieser Funktionalität ist ein \textbf{Notfallplan} bei einem Sicherheitsvorfall gegeben.

Um die Verfügbarkeit von Vault zu erhöhen, kann die \textbf{Hochverfügbarkeitsfunktion} aktiviert werden und der Vault-Server Dienst kann auf mehreren Servern gleichzeitig laufen. Die eigentliche Schwachstelle im Bezug auf die Verfügbarkeit ergibt sich jedoch auch dem Key-Value Speicher im Hintergrund. Bei der Wahl des Speichers sollte darauf geachtet werden, dass die Technologie über Ausfallsicherheitsoptionen verfügt. Wie in Listing \vref{lst:unseal} zu sehen ist wird der Status der Hochverfügbarkeitsfunktion in der Ausgabe unter dem Feld ``HA Enabled`` gezeigt.

Einen die Auditlog funktion kann durch das Kommando \inline|vault audit enable [file socket syslog]| aktiviert werden. Dabei wird mit den Schlüsselwörtern ``file``, ``socket`` und ``syslog`` das Ziel des Auditlogs angegeben.
 
\newpage
\section{Fazit und Ausblick}
\label{sec:ausblick}

Hashicorp Vault stellt sich als brauchbare Lösung zum Management von geheimen Informationen dar und wird diesem Anspruch auch gerecht. Der Fokus liegt dabei eindeutig auf der Verwendung in Cloudumgebungen. Die Installation ist sehr einfach und die Bereitstellung der Software also einzelne Datei ist komfortabel. In der von mir zu Beginn des Projekts verwendeten Version von Vault (Version 0.8.3) sind sehr viele Funktionen die für den produktiven Einsatz in großen Unternehmen nützlich sind ausschließlich in der kostenpflichtigen Variante verfügbar und konnten daher von mir nicht getestet werden. Seit Version 0.9.3 ist jedoch auch die Funktion der graphischen Oberfläche in die kostenfreie Version übergegangen und fügt damit einen wichtigen Faktor was die Benutzerfreundlichkeit angeht hinzu.\newline
  




%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%%% end main document
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\Urlmuskip=0mu plus 1mu
\bibliographystyle{plain}
\bibliography{literatur}

\end{onehalfspacing}
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

